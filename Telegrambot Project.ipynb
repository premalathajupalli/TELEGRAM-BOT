{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":157},"executionInfo":{"elapsed":2686,"status":"ok","timestamp":1716632722273,"user":{"displayName":"jupalli premalatha","userId":"02044694377993092240"},"user_tz":-330},"id":"EdkA3ejTnrnu","outputId":"488690c8-78fd-4ced-a357-bb01dae1d97a"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["strong king\n","['question', 'answer']\n"]},{"output_type":"execute_result","data":{"text/plain":["'People with COVID-19 have reported a wide range of symptoms – from mild symptoms to severe illness. Symptoms may appear 2-14 days after exposure to the virus. If you have fever, cough, or other symptoms, you might have COVID-19.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"source":["import pandas as pd\n","import numpy as np\n","import string\n","import re\n","import nltk\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","data=pd.read_csv('/content/covid 19.csv')\n","from nltk.corpus import stopwords\n","\n","stop_words = set(stopwords.words('english'))\n","\n","sentence = \"I am a strong king\"\n","words = sentence.lower().split()\n","filtered_words = [w for w in words if w not in stop_words]\n","result = \" \".join(filtered_words)\n","print(result)\n","import nltk\n","from nltk.stem import WordNetLemmatizer\n","lemmatizer=WordNetLemmatizer()\n","# import the lemmatizer module\n","from nltk.stem import WordNetLemmatizer\n","\n","# create an instance of the lemmatizer\n","wnl = WordNetLemmatizer()\n","\n","# assume the dataset is a list of words\n","dataset= data\n","\n","# create an empty list to store the lemmatized words\n","lemmatized_dataset = []\n","\n","# iterate over the dataset and apply the lemmatizer to each word\n","for word in dataset:\n","  # lemmatize the word and append it to the lemmatized_dataset list\n","  lemma = wnl.lemmatize(word)\n","  lemmatized_dataset.append(lemma)\n","\n","# print the lemmatized_dataset list\n","print(lemmatized_dataset)\n","#vectoriser\n","corpus=data['questions'].values\n","corpus\n","from sklearn.feature_extraction.text import CountVectorizer\n","bw_vect=CountVectorizer()\n","bw_fit=bw_vect.fit(corpus)\n","bw_corpus=bw_fit.transform(corpus)\n","\n","bw_corpus.shape\n","bw_corpus.toarray()\n","bw_fit.get_feature_names_out()\n","cv_data=pd.DataFrame(bw_corpus.toarray(),columns=bw_fit.get_feature_names_out())\n","cv_data\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","tf_vect=TfidfVectorizer(max_features=5000)\n","tfidf_fit=tf_vect.fit(corpus)\n","tfidf_corpus=tfidf_fit.transform(corpus)\n","tfidf_fit.get_feature_names_out()\n","tfidf_data=pd.DataFrame(tfidf_corpus.toarray(),columns=tfidf_fit.get_feature_names_out())\n","tfidf_data\n","test=\"what are the symptomns of covid\"\n","tfidf_test=tfidf_fit.transform([test])\n","mask=tfidf_test.toarray()!=0\n","m=mask[0]\n","m\n","tfidf_test.toarray()[mask]\n","from sklearn.metrics.pairwise import cosine_similarity\n","cm=cosine_similarity(tfidf_test,tfidf_corpus)\n","cm[0]\n","import numpy as np\n","pos=np.argmax(cm[0])\n","data.iloc[pos]\n","data.answers[pos]"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9193,"status":"ok","timestamp":1716632736773,"user":{"displayName":"jupalli premalatha","userId":"02044694377993092240"},"user_tz":-330},"id":"MzTPTGDyr6ND","outputId":"3f686dee-2136-4a51-c0bf-c29809e55cfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyTelegramBotAPI\n","  Downloading pytelegrambotapi-4.18.1-py3-none-any.whl (242 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m174.1/242.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.9/242.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pyTelegramBotAPI) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (2024.2.2)\n","Installing collected packages: pyTelegramBotAPI\n","Successfully installed pyTelegramBotAPI-4.18.1\n"]}],"source":["pip install pyTelegramBotAPI\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C25DiAVKyawb","outputId":"16839921-e4f0-4db3-e93e-6349d2950d1c","executionInfo":{"status":"ok","timestamp":1716632836523,"user_tz":-330,"elapsed":84683,"user":{"displayName":"jupalli premalatha","userId":"02044694377993092240"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import telebot\n","import numpy as np\n","import pandas as pd\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","data = pd.read_csv('/content/covid 19.csv')\n","wnl = WordNetLemmatizer()\n","dataset = data['questions']\n","lemmatized_dataset = [wnl.lemmatize(word) for word in dataset]\n","tf_vect = TfidfVectorizer(max_features=5000)\n","tfidf_fit = tf_vect.fit(lemmatized_dataset)\n","tfidf_corpus = tfidf_fit.transform(lemmatized_dataset)\n","bot = telebot.TeleBot(\"5735111956:AAHr-8mqSJ4htmSyAI6qvcVBjGcjNUs8sLM\")\n","@bot.message_handler(commands=['start', 'help'])\n","def send_welcome(message):\n","    bot.reply_to(message, \"Hello! Welcome to the COVID-19 Bot. Please enter your question about COVID-19.\")\n","\n","@bot.message_handler(func=lambda message: True)\n","def handle_message(message):\n","    input_text = message.text\n","\n","    # Process the input text\n","    output_text = process_input(input_text)\n","\n","    # Reply with the output in Telegram chat\n","    bot.reply_to(message, output_text)\n","def process_input(input_text):\n","    lemmatized_query = wnl.lemmatize(input_text)\n","    tfidf_test = tfidf_fit.transform([lemmatized_query])\n","    cm = cosine_similarity(tfidf_test, tfidf_corpus)\n","    pos = np.argmax(cm[0])\n","    predicted_question = dataset.iloc[pos]\n","    predicted_answer = data['answers'].iloc[pos]\n","\n","    if cm[0][pos] < 0.5:\n","        return \"I'm sorry, but I couldn't find a relevant answer to your question.\"\n","\n","    return f\"Question: {predicted_question}\\n\\nAnswer: {predicted_answer}\"\n","bot.polling()\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMyl3CqvWHrlFE2PQbuIwLL"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}